#!/usr/bin/env node

/**
 * docs â†’ RAG çŸ¥è¯†åº“åŒæ­¥è„šæœ¬
 * 
 * ç”¨æ³•ï¼š
 *   node scripts/sync-to-rag.js              # æ­£å¸¸åŒæ­¥
 *   node scripts/sync-to-rag.js --dry-run    # é¢„è§ˆå˜æ›´ï¼Œä¸æ‰§è¡Œ
 * 
 * ä¾èµ–ï¼šnpm install gray-matter
 * 
 * åœ¨ package.json ä¸­æ·»åŠ ï¼š
 *   "sync-rag": "node scripts/sync-to-rag.js"
 *   "sync-rag:dry": "node scripts/sync-to-rag.js --dry-run"
 */

const fs = require('fs');
const path = require('path');
const crypto = require('crypto');
const matter = require('gray-matter');

// ============ é…ç½® ============

const CONFIG = {
  docsDir: path.resolve(__dirname, '..', 'docs'),
  hashFile: path.resolve(__dirname, '..', '.rag-sync-hashes.json'),
  ragBaseUrl: process.env.RAG_URL || 'http://localhost:3003',
  collection: process.env.RAG_COLLECTION || 'product_help',
  dryRun: process.argv.includes('--dry-run'),
};

// ============ Markdown åˆ†å— ============

function splitByHeadings(content) {
  const lines = content.split('\n');
  const chunks = [];
  let currentHeading = '';
  let currentLines = [];

  for (const line of lines) {
    const headingMatch = line.match(/^(#{2,3})\s+(.+)/);
    if (headingMatch) {
      // ä¿å­˜ä¸Šä¸€ä¸ª chunk
      if (currentLines.length > 0) {
        const text = currentLines.join('\n').trim();
        if (text) chunks.push({ heading: currentHeading, text });
      }
      currentHeading = headingMatch[2].trim();
      currentLines = [];
    } else {
      currentLines.push(line);
    }
  }

  // æœ€åä¸€ä¸ª chunk
  if (currentLines.length > 0) {
    const text = currentLines.join('\n').trim();
    if (text) chunks.push({ heading: currentHeading, text });
  }

  return chunks;
}

// ============ Hash ç®¡ç† ============

function loadHashes() {
  if (fs.existsSync(CONFIG.hashFile)) {
    return JSON.parse(fs.readFileSync(CONFIG.hashFile, 'utf-8'));
  }
  return {};
}

function saveHashes(hashes) {
  fs.writeFileSync(CONFIG.hashFile, JSON.stringify(hashes, null, 2));
}

function computeHash(content) {
  return crypto.createHash('md5').update(content).digest('hex').slice(0, 12);
}

// ============ RAG API è°ƒç”¨ ============

async function ragDelete(docId) {
  const res = await fetch(`${CONFIG.ragBaseUrl}/delete`, {
    method: 'POST',
    headers: { 'Content-Type': 'application/json' },
    body: JSON.stringify({ collection: CONFIG.collection, doc_id: docId }),
  });
  if (!res.ok) throw new Error(`DELETE ${docId} failed: ${res.status}`);
}

async function ragIndex(documents, metadatas) {
  const res = await fetch(`${CONFIG.ragBaseUrl}/index`, {
    method: 'POST',
    headers: { 'Content-Type': 'application/json' },
    body: JSON.stringify({
      collection: CONFIG.collection,
      documents,
      metadatas,
    }),
  });
  if (!res.ok) throw new Error(`INDEX failed: ${res.status}`);
}

// ============ ä¸»æµç¨‹ ============

async function main() {
  console.log(CONFIG.dryRun ? 'ğŸ” DRY RUN æ¨¡å¼\n' : 'ğŸš€ å¼€å§‹åŒæ­¥\n');

  const oldHashes = loadHashes();
  const newHashes = {};

  // æ‰«æ docs ç›®å½•
  const files = fs.readdirSync(CONFIG.docsDir)
    .filter(f => f.endsWith('.md') || f.endsWith('.mdx'));

  let added = 0, updated = 0, deleted = 0, skipped = 0;

  for (const file of files) {
    const filePath = path.join(CONFIG.docsDir, file);
    const raw = fs.readFileSync(filePath, 'utf-8');
    const { data: fm, content } = matter(raw);

    const docId = `docs/${file.replace(/\.mdx?$/, '')}`;

    // rag: false æˆ–æœªå£°æ˜ â†’ è·³è¿‡ï¼ˆå¦‚æœä¹‹å‰åŒæ­¥è¿‡åˆ™åˆ é™¤ï¼‰
    if (!fm.rag) {
      if (oldHashes[docId]) {
        console.log(`ğŸ—‘  åˆ é™¤ (rag:false): ${docId}`);
        if (!CONFIG.dryRun) await ragDelete(docId);
        deleted++;
      }
      continue;
    }

    const hash = computeHash(raw);
    newHashes[docId] = hash;

    // æ— å˜æ›´ â†’ è·³è¿‡
    if (oldHashes[docId] === hash) {
      skipped++;
      continue;
    }

    // åˆ†å—
    const chunks = splitByHeadings(content);
    if (chunks.length === 0) {
      skipped++;
      continue;
    }

    const documents = chunks.map(c =>
      c.heading ? `## ${c.heading}\n\n${c.text}` : c.text
    );

    const metadatas = chunks.map(c => ({
      doc_id: docId,
      source: file,
      title: fm.title || file,
      section: c.heading || 'æ¦‚è¿°',
      tags: (fm.rag_tags || []).join(','),
    }));

    const action = oldHashes[docId] ? 'æ›´æ–°' : 'æ–°å¢';
    console.log(`${action === 'æ–°å¢' ? 'â•' : 'ğŸ”„'}  ${action}: ${docId} (${chunks.length} chunks)`);

    if (!CONFIG.dryRun) {
      // å…ˆåˆ åå¢
      if (oldHashes[docId]) await ragDelete(docId);
      await ragIndex(documents, metadatas);
    }

    action === 'æ–°å¢' ? added++ : updated++;
  }

  // æ¸…ç†å·²åˆ é™¤çš„æ–‡ä»¶
  for (const docId of Object.keys(oldHashes)) {
    if (!newHashes[docId] && !files.some(f => `docs/${f.replace(/\.mdx?$/, '')}` === docId && matter(fs.readFileSync(path.join(CONFIG.docsDir, f), 'utf-8')).data.rag === false)) {
      // æ–‡ä»¶å·²ä¸å­˜åœ¨
      const exists = files.some(f => `docs/${f.replace(/\.mdx?$/, '')}` === docId);
      if (!exists) {
        console.log(`ğŸ—‘  åˆ é™¤ (æ–‡ä»¶å·²ç§»é™¤): ${docId}`);
        if (!CONFIG.dryRun) await ragDelete(docId);
        deleted++;
      }
    }
  }

  // ä¿å­˜ hash
  if (!CONFIG.dryRun) saveHashes(newHashes);

  console.log(`\nâœ… å®Œæˆ: æ–°å¢ ${added}, æ›´æ–° ${updated}, åˆ é™¤ ${deleted}, è·³è¿‡ ${skipped}`);
}

main().catch(err => {
  console.error('âŒ åŒæ­¥å¤±è´¥:', err.message);
  process.exit(1);
});
