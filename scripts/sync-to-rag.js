#!/usr/bin/env node

/**
 * docs â†’ RAG çŸ¥è¯†åº“åŒæ­¥è„šæœ¬
 *
 * ç”¨æ³•ï¼š
 *   node scripts/sync-to-rag.js              # æ­£å¸¸åŒæ­¥
 *   node scripts/sync-to-rag.js --dry-run    # é¢„è§ˆå˜æ›´ï¼Œä¸æ‰§è¡Œ
 *
 * ä¾èµ–ï¼šnpm install gray-matter dotenv
 *
 * åœ¨ package.json ä¸­æ·»åŠ ï¼š
 *   "sync-rag": "node scripts/sync-to-rag.js"
 *   "sync-rag:dry": "node scripts/sync-to-rag.js --dry-run"
 */

const fs = require('fs');
const path = require('path');
const crypto = require('crypto');
const matter = require('gray-matter');

// åŠ è½½ç¯å¢ƒå˜é‡
require('dotenv').config({ path: path.resolve(__dirname, '..', '.env.local') });

// ============ é…ç½® ============

const CONFIG = {
  docsDir: path.resolve(__dirname, '..', 'docs'),
  hashFile: path.resolve(__dirname, '..', '.rag-sync-hashes.json'),
  ragBaseUrl: process.env.RAG_URL || 'http://localhost:3003',
  collection: process.env.RAG_COLLECTION || 'product_help',
  apiKey: process.env.RAG_API_KEY || '',
  dryRun: process.argv.includes('--dry-run'),
};

// ============ Markdown åˆ†å— ============
// å¯¹é½ rag-service: å›ºå®š 500 token/å— (çº¦750å­—), é‡å  50 token

function splitByTokens(content) {
  const CHUNK_SIZE = 750;  // çº¦ 500 token
  const OVERLAP = 75;      // çº¦ 50 token

  const chunks = [];
  let pos = 0;

  while (pos < content.length) {
    const end = Math.min(pos + CHUNK_SIZE, content.length);

    // å°è¯•åœ¨å¥å­è¾¹ç•Œåˆ‡åˆ†
    let splitPos = end;
    if (end < content.length) {
      // å¯»æ‰¾æœ€è¿‘çš„å¥å­ç»“æŸç¬¦
      const sentenceEnd = content.lastIndexOf('\n', end);
      if (sentenceEnd > pos + CHUNK_SIZE / 2) {
        splitPos = sentenceEnd + 1;
      }
    }

    chunks.push(content.slice(pos, splitPos).trim());
    pos = splitPos - OVERLAP;
  }

  return chunks.filter(c => c.length > 0);
}

// ============ Hash ç®¡ç† ============

function loadHashes() {
  if (fs.existsSync(CONFIG.hashFile)) {
    return JSON.parse(fs.readFileSync(CONFIG.hashFile, 'utf-8'));
  }
  return {};
}

function saveHashes(hashes) {
  fs.writeFileSync(CONFIG.hashFile, JSON.stringify(hashes, null, 2));
}

function computeHash(content) {
  return crypto.createHash('md5').update(content).digest('hex').slice(0, 12);
}

// ============ RAG API è°ƒç”¨ ============

async function ragDelete(docId) {
  const url = `${CONFIG.ragBaseUrl}/documents?collection=${CONFIG.collection}&doc_id=${docId}`;
  const res = await fetch(url, {
    method: 'DELETE',
    headers: { 'X-API-Key': CONFIG.apiKey },
  });
  if (!res.ok) throw new Error(`DELETE ${docId} failed: ${res.status}`);
}

async function ragIndex(documents, metadatas) {
  const res = await fetch(`${CONFIG.ragBaseUrl}/index`, {
    method: 'POST',
    headers: { 'Content-Type': 'application/json' },
    body: JSON.stringify({
      collection: CONFIG.collection,
      documents: documents,
      metadatas: metadatas,
      api_key: CONFIG.apiKey,
    }),
  });
  if (!res.ok) {
    const err = await res.text();
    throw new Error(`INDEX failed: ${res.status} - ${err}`);
  }
}

// ============ ä¸»æµç¨‹ ============

async function main() {
  console.log(CONFIG.dryRun ? 'ğŸ” DRY RUN æ¨¡å¼\n' : 'ğŸš€ å¼€å§‹åŒæ­¥\n');

  const oldHashes = loadHashes();
  const newHashes = {};

  // æ‰«æ docs ç›®å½•
  const files = fs.readdirSync(CONFIG.docsDir)
    .filter(f => f.endsWith('.md') || f.endsWith('.mdx'));

  let added = 0, updated = 0, deleted = 0, skipped = 0;

  for (const file of files) {
    const filePath = path.join(CONFIG.docsDir, file);
    const raw = fs.readFileSync(filePath, 'utf-8');
    const { data: fm, content } = matter(raw);

    const docId = `docs/${file.replace(/\.mdx?$/, '')}`;

    // rag: false æˆ–æœªå£°æ˜ â†’ è·³è¿‡ï¼ˆå¦‚æœä¹‹å‰åŒæ­¥è¿‡åˆ™åˆ é™¤ï¼‰
    if (!fm.rag) {
      if (oldHashes[docId]) {
        console.log(`ğŸ—‘  åˆ é™¤ (rag:false): ${docId}`);
        if (!CONFIG.dryRun) await ragDelete(docId);
        deleted++;
      }
      continue;
    }

    const hash = computeHash(raw);
    newHashes[docId] = hash;

    // æ— å˜æ›´ â†’ è·³è¿‡
    if (oldHashes[docId] === hash) {
      skipped++;
      continue;
    }

    // åˆ†å—
    const chunks = splitByTokens(content);
    if (chunks.length === 0) {
      skipped++;
      continue;
    }

    const documents = chunks;

    const metadatas = chunks.map((_, i) => ({
      doc_id: docId,
      source: file,
      title: fm.title || file,
      section: `chunk_${i}`,
      tags: (fm.rag_tags || []).join(','),
      project: fm.project || 'general',
    }));

    const action = oldHashes[docId] ? 'æ›´æ–°' : 'æ–°å¢';
    console.log(`${action === 'æ–°å¢' ? 'â•' : 'ğŸ”„'}  ${action}: ${docId} (${chunks.length} chunks)`);

    if (!CONFIG.dryRun) {
      // è°ƒè¯•æ—¥å¿—
      console.log(`  [DEBUG] documents: ${documents.length}, metadatas: ${metadatas.length}`);
      console.log(`  [DEBUG] first metadata:`, JSON.stringify(metadatas[0]));

      // å…ˆåˆ åå¢
      if (oldHashes[docId]) await ragDelete(docId);
      await ragIndex(documents, metadatas);
    }

    action === 'æ–°å¢' ? added++ : updated++;
  }

  // æ¸…ç†å·²åˆ é™¤çš„æ–‡ä»¶
  for (const docId of Object.keys(oldHashes)) {
    if (!newHashes[docId] && !files.some(f => `docs/${f.replace(/\.mdx?$/, '')}` === docId && matter(fs.readFileSync(path.join(CONFIG.docsDir, f), 'utf-8')).data.rag === false)) {
      // æ–‡ä»¶å·²ä¸å­˜åœ¨
      const exists = files.some(f => `docs/${f.replace(/\.mdx?$/, '')}` === docId);
      if (!exists) {
        console.log(`ğŸ—‘  åˆ é™¤ (æ–‡ä»¶å·²ç§»é™¤): ${docId}`);
        if (!CONFIG.dryRun) await ragDelete(docId);
        deleted++;
      }
    }
  }

  // ä¿å­˜ hash
  if (!CONFIG.dryRun) saveHashes(newHashes);

  console.log(`\nâœ… å®Œæˆ: æ–°å¢ ${added}, æ›´æ–° ${updated}, åˆ é™¤ ${deleted}, è·³è¿‡ ${skipped}`);
}

main().catch(err => {
  console.error('âŒ åŒæ­¥å¤±è´¥:', err.message);
  process.exit(1);
});
